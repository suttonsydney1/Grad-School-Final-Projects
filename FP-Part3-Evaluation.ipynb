{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Unbiased Evaluation using a New Test Set\n",
    "\n",
    "In this part, we are given a new test set (`/dsa/data/all_datasets/back_order/Kaggle_Test_Dataset_v2.csv`). We can now take advantage of the entire smart sample that we created in Part I. \n",
    "\n",
    "* Retrain a pipeline using the optimal parameters that the pipeline learned. We don't need to repeat GridSearch here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.covariance import EllipticEnvelope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load smart sample and the best pipeline from Part II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_X, sampled_y, model = joblib.load('sample-data-v1.pkl')\n",
    "pipe2, model_grid2 = joblib.load('data-part-3.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##  Retrain a pipeline using the full sampled training data set\n",
    "\n",
    "Use the full sampled training data set to train the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code below this comment  (Question #E301)\n",
    "# ----------------------------------\n",
    "\n",
    "trained_model = model_grid2.fit(sampled_X, sampled_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the trained model with the pickle library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trained-model.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add code below this comment  \n",
    "# -----------------------------\n",
    "\n",
    "joblib.dump(trained_model, 'trained-model.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Load the Testing Data and evaluate your model\n",
    "\n",
    " * `/dsa/data/all_datasets/back_order/Kaggle_Test_Dataset_v2.csv`\n",
    " \n",
    "* We need to preprocess this test data (follow the steps similar to Part I)\n",
    "* If we have fitted any normalizer/standardizer in Part 2, then we have to transform this test data using the fitted normalizer/standardizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 242076 entries, 0 to 242075\n",
      "Data columns (total 23 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   sku                242076 non-null  object \n",
      " 1   national_inv       242075 non-null  float64\n",
      " 2   lead_time          227351 non-null  float64\n",
      " 3   in_transit_qty     242075 non-null  float64\n",
      " 4   forecast_3_month   242075 non-null  float64\n",
      " 5   forecast_6_month   242075 non-null  float64\n",
      " 6   forecast_9_month   242075 non-null  float64\n",
      " 7   sales_1_month      242075 non-null  float64\n",
      " 8   sales_3_month      242075 non-null  float64\n",
      " 9   sales_6_month      242075 non-null  float64\n",
      " 10  sales_9_month      242075 non-null  float64\n",
      " 11  min_bank           242075 non-null  float64\n",
      " 12  potential_issue    242075 non-null  object \n",
      " 13  pieces_past_due    242075 non-null  float64\n",
      " 14  perf_6_month_avg   242075 non-null  float64\n",
      " 15  perf_12_month_avg  242075 non-null  float64\n",
      " 16  local_bo_qty       242075 non-null  float64\n",
      " 17  deck_risk          242075 non-null  object \n",
      " 18  oe_constraint      242075 non-null  object \n",
      " 19  ppap_risk          242075 non-null  object \n",
      " 20  stop_auto_buy      242075 non-null  object \n",
      " 21  rev_stop           242075 non-null  object \n",
      " 22  went_on_backorder  242075 non-null  object \n",
      "dtypes: float64(15), object(8)\n",
      "memory usage: 42.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the given test set  (Question #E302)\n",
    "# ----------------------------------\n",
    "\n",
    "DATASET = '/dsa/data/all_datasets/back_order/Kaggle_Test_Dataset_v2.csv'\n",
    "dataset = pd.read_csv(DATASET).sample(frac = 1).reset_index(drop=True)\n",
    "dataset.head().transpose()\n",
    "\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>national_inv</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>in_transit_qty</th>\n",
       "      <th>forecast_3_month</th>\n",
       "      <th>forecast_6_month</th>\n",
       "      <th>forecast_9_month</th>\n",
       "      <th>sales_1_month</th>\n",
       "      <th>sales_3_month</th>\n",
       "      <th>sales_6_month</th>\n",
       "      <th>sales_9_month</th>\n",
       "      <th>...</th>\n",
       "      <th>pieces_past_due</th>\n",
       "      <th>perf_6_month_avg</th>\n",
       "      <th>perf_12_month_avg</th>\n",
       "      <th>local_bo_qty</th>\n",
       "      <th>deck_risk</th>\n",
       "      <th>oe_constraint</th>\n",
       "      <th>ppap_risk</th>\n",
       "      <th>stop_auto_buy</th>\n",
       "      <th>rev_stop</th>\n",
       "      <th>went_on_backorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>207.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>109.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242071</th>\n",
       "      <td>49.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242072</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242073</th>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242074</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242075</th>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>227351 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        national_inv  lead_time  in_transit_qty  forecast_3_month  \\\n",
       "0              207.0        2.0             0.0               0.0   \n",
       "2                3.0       12.0             0.0               0.0   \n",
       "3                2.0        4.0             0.0               0.0   \n",
       "4                5.0        4.0             0.0               3.0   \n",
       "5              109.0        8.0             0.0               0.0   \n",
       "...              ...        ...             ...               ...   \n",
       "242071          49.0       12.0             1.0               7.0   \n",
       "242072           1.0        8.0             0.0               1.0   \n",
       "242073           6.0        8.0             0.0               0.0   \n",
       "242074           2.0        8.0             0.0               0.0   \n",
       "242075          10.0       12.0             0.0               0.0   \n",
       "\n",
       "        forecast_6_month  forecast_9_month  sales_1_month  sales_3_month  \\\n",
       "0                    0.0               0.0            0.0            0.0   \n",
       "2                    0.0               0.0            0.0            0.0   \n",
       "3                    0.0               0.0            0.0            0.0   \n",
       "4                    6.0              12.0            0.0            2.0   \n",
       "5                    0.0               0.0            0.0            0.0   \n",
       "...                  ...               ...            ...            ...   \n",
       "242071              31.0              61.0            3.0           21.0   \n",
       "242072               1.0               2.0            0.0            1.0   \n",
       "242073               0.0               0.0            0.0            0.0   \n",
       "242074               0.0               0.0            0.0            0.0   \n",
       "242075               0.0               0.0            0.0            0.0   \n",
       "\n",
       "        sales_6_month  sales_9_month  ...  pieces_past_due perf_6_month_avg  \\\n",
       "0                 0.0           20.0  ...              0.0             0.96   \n",
       "2                 0.0            0.0  ...              0.0             0.73   \n",
       "3                 0.0            0.0  ...              0.0             0.73   \n",
       "4                 3.0            3.0  ...              0.0             0.96   \n",
       "5                 0.0            0.0  ...              0.0             0.99   \n",
       "...               ...            ...  ...              ...              ...   \n",
       "242071           56.0           85.0  ...              0.0             0.99   \n",
       "242072            1.0            2.0  ...              0.0             0.98   \n",
       "242073            0.0            0.0  ...              0.0             0.82   \n",
       "242074            1.0            1.0  ...              0.0             0.98   \n",
       "242075            0.0            0.0  ...              0.0             0.48   \n",
       "\n",
       "        perf_12_month_avg  local_bo_qty  deck_risk  oe_constraint ppap_risk  \\\n",
       "0                    0.98           0.0         No             No        No   \n",
       "2                    0.79           0.0        Yes             No        No   \n",
       "3                    0.78           0.0         No             No        No   \n",
       "4                    0.91           0.0         No             No        No   \n",
       "5                    0.98           0.0         No             No        No   \n",
       "...                   ...           ...        ...            ...       ...   \n",
       "242071               0.99           0.0         No             No        No   \n",
       "242072               0.98           0.0         No             No        No   \n",
       "242073               0.81           0.0         No             No        No   \n",
       "242074               0.98           0.0         No             No        No   \n",
       "242075               0.48           0.0        Yes             No        No   \n",
       "\n",
       "       stop_auto_buy rev_stop went_on_backorder  \n",
       "0                Yes       No                No  \n",
       "2                Yes       No                No  \n",
       "3                Yes       No                No  \n",
       "4                Yes       No                No  \n",
       "5                Yes       No                No  \n",
       "...              ...      ...               ...  \n",
       "242071           Yes       No                No  \n",
       "242072           Yes       No                No  \n",
       "242073           Yes       No                No  \n",
       "242074           Yes       No                No  \n",
       "242075           Yes       No                No  \n",
       "\n",
       "[227351 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del_cols = ['sku']\n",
    "dataset.drop(del_cols, axis=1, inplace=True)\n",
    "\n",
    "dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['potential_issue', 'deck_risk', 'oe_constraint', 'ppap_risk', 'stop_auto_buy', 'rev_stop', 'went_on_backorder']\n",
      "potential_issue ['No' 'Yes' nan]\n",
      "deck_risk ['No' 'Yes' nan]\n",
      "oe_constraint ['No' 'Yes' nan]\n",
      "ppap_risk ['No' 'Yes' nan]\n",
      "stop_auto_buy ['Yes' 'No' nan]\n",
      "rev_stop ['No' 'Yes' nan]\n",
      "went_on_backorder ['No' 'Yes' nan]\n"
     ]
    }
   ],
   "source": [
    "yes_no_columns = list(filter(lambda i: dataset[i].dtype!=np.float64, dataset.columns))\n",
    "print(yes_no_columns)\n",
    "\n",
    "# Add code below this comment  (Question #E102)\n",
    "# ----------------------------------\n",
    "\n",
    "print('potential_issue', dataset['potential_issue'].unique())\n",
    "print('deck_risk', dataset['deck_risk'].unique())\n",
    "print('oe_constraint', dataset['oe_constraint'].unique())\n",
    "print('ppap_risk', dataset['ppap_risk'].unique())\n",
    "print('stop_auto_buy', dataset['stop_auto_buy'].unique())\n",
    "print('rev_stop', dataset['rev_stop'].unique())\n",
    "print('went_on_backorder', dataset['went_on_backorder'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling missing values of potential_issue with No\n",
      "Filling missing values of deck_risk with No\n",
      "Filling missing values of oe_constraint with No\n",
      "Filling missing values of ppap_risk with No\n",
      "Filling missing values of stop_auto_buy with Yes\n",
      "Filling missing values of rev_stop with No\n",
      "Filling missing values of went_on_backorder with No\n"
     ]
    }
   ],
   "source": [
    "for column_name in yes_no_columns:\n",
    "    mode = dataset[column_name].apply(str).mode()[0]\n",
    "    print('Filling missing values of {} with {}'.format(column_name, mode))\n",
    "    dataset[column_name].fillna(mode, inplace=True)\n",
    "    \n",
    "dataset['potential_issue'] = dataset['potential_issue'].map({'No':0, 'Yes':1})\n",
    "dataset['deck_risk'] = dataset['deck_risk'].map({'No':0, 'Yes':1})\n",
    "dataset['oe_constraint'] = dataset['oe_constraint'].map({'No':0, 'Yes':1})\n",
    "dataset['ppap_risk'] = dataset['ppap_risk'].map({'No':0, 'Yes':1})\n",
    "dataset['stop_auto_buy'] = dataset['stop_auto_buy'].map({'No':0, 'Yes':1})\n",
    "dataset['rev_stop'] = dataset['rev_stop'].map({'No':0, 'Yes':1})\n",
    "dataset['went_on_backorder'] = dataset['went_on_backorder'].map({'No':0, 'Yes':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "national_inv             1\n",
       "lead_time            14725\n",
       "in_transit_qty           1\n",
       "forecast_3_month         1\n",
       "forecast_6_month         1\n",
       "forecast_9_month         1\n",
       "sales_1_month            1\n",
       "sales_3_month            1\n",
       "sales_6_month            1\n",
       "sales_9_month            1\n",
       "min_bank                 1\n",
       "potential_issue          0\n",
       "pieces_past_due          1\n",
       "perf_6_month_avg         1\n",
       "perf_12_month_avg        1\n",
       "local_bo_qty             1\n",
       "deck_risk                0\n",
       "oe_constraint            0\n",
       "ppap_risk                0\n",
       "stop_auto_buy            0\n",
       "rev_stop                 0\n",
       "went_on_backorder        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling missing values of national_inv with 2.0\n",
      "Filling missing values of lead_time with 8.0\n",
      "Filling missing values of in_transit_qty with 0.0\n",
      "Filling missing values of forecast_3_month with 0.0\n",
      "Filling missing values of forecast_6_month with 0.0\n",
      "Filling missing values of forecast_9_month with 0.0\n",
      "Filling missing values of sales_1_month with 0.0\n",
      "Filling missing values of sales_3_month with 0.0\n",
      "Filling missing values of sales_6_month with 0.0\n",
      "Filling missing values of sales_9_month with 0.0\n",
      "Filling missing values of min_bank with 0.0\n",
      "Filling missing values of pieces_past_due with 0.0\n",
      "Filling missing values of perf_6_month_avg with 0.73\n",
      "Filling missing values of perf_12_month_avg with 0.99\n",
      "Filling missing values of local_bo_qty with 0.0\n"
     ]
    }
   ],
   "source": [
    "dataset_fillna = list(filter(lambda i: dataset[i].isna().sum() >= 1, dataset.columns))\n",
    "\n",
    "for column_name in dataset_fillna:\n",
    "    mode = dataset[column_name].apply(str).mode()[0]\n",
    "    print('Filling missing values of {} with {}'.format(column_name, mode))\n",
    "    dataset[column_name].fillna(mode, inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "national_inv         0\n",
       "lead_time            0\n",
       "in_transit_qty       0\n",
       "forecast_3_month     0\n",
       "forecast_6_month     0\n",
       "forecast_9_month     0\n",
       "sales_1_month        0\n",
       "sales_3_month        0\n",
       "sales_6_month        0\n",
       "sales_9_month        0\n",
       "min_bank             0\n",
       "potential_issue      0\n",
       "pieces_past_due      0\n",
       "perf_6_month_avg     0\n",
       "perf_12_month_avg    0\n",
       "local_bo_qty         0\n",
       "deck_risk            0\n",
       "oe_constraint        0\n",
       "ppap_risk            0\n",
       "stop_auto_buy        0\n",
       "rev_stop             0\n",
       "went_on_backorder    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = dataset.drop('went_on_backorder', axis=1)\n",
    "y_test = dataset.went_on_backorder\n",
    "\n",
    "processor = MinMaxScaler()\n",
    "scaled_X = processor.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now predict and evaluate with the preprocessed test set. It would be interesting to see the performance with and without outliers removal from the test set. We can report confusion matrix, precision, recall, f1-score, accuracy, and other measures (if any). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.79      0.88    239388\n",
      "           1       0.03      0.55      0.05      2688\n",
      "\n",
      "    accuracy                           0.79    242076\n",
      "   macro avg       0.51      0.67      0.47    242076\n",
      "weighted avg       0.98      0.79      0.87    242076\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>188705</td>\n",
       "      <td>50683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1213</td>\n",
       "      <td>1475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1\n",
       "0  188705  50683\n",
       "1    1213   1475"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add code below this comment  (Question #E303)\n",
    "# ----------------------------------\n",
    "\n",
    "\n",
    "#without outlier removal\n",
    "pred_y = trained_model.predict(X_test)\n",
    "\n",
    "model_grid2.score(X_test, y_test)\n",
    "print(classification_report(y_test, pred_y))\n",
    "pd.DataFrame(confusion_matrix(y_test, pred_y))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Write a summary of your processing and an analysis of the model performance  \n",
    "# (Question #E304)\n",
    "# ----------------------------------\n",
    "\n",
    "The model performed generally well, but not exceptionally, with an accurarcy of 79%. As the confusion matrix shows, this does a good job of predicting accurately if something is not on backorder, however often classifies something as on backorder when it isn't.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflect\n",
    "\n",
    "Imagine you are data scientist that has been tasked with developing a system to save your \n",
    "company money by predicting and preventing back orders of parts in the supply chain.\n",
    "\n",
    "Write a **brief summary** for \"management\" that details your findings, \n",
    "your level of certainty and trust in the models, \n",
    "and recommendations for operationalizing these models for the business."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Write your answer here:  \n",
    "# (Question #E305)\n",
    "# ----------------------------------\n",
    "\n",
    "\n",
    "The model created will help the company save money by predicting with 79% accuracy if something will go on back order. Utilizing and continuing to fine tune this model will be a great way to improve the current system in place and help identify potential future needs. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook!\n",
    "## Then `File > Close and Halt`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
